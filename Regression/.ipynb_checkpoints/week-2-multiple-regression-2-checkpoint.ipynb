{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv')\n",
    "#train_data , test_data = train_test_split(sales, test_size=0.2)\n",
    "train_data = pd.read_csv('kc_house_train_data.csv')\n",
    "test_data = pd.read_csv('kc_house_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    data_frame['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_frame = data_frame[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_array = data_frame[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_array.as_matrix()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1 1180]\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "print (example_features[0]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print (example_output[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.])\n",
    "my_features = example_features[0,:]\n",
    "predicted_value = np.dot(my_weights, my_features)\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print (test_predictions[0]) # should be 1181.0\n",
    "print (test_predictions[1]) # should be 2571.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative = 2*np.dot(errors, feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850016.0\n",
      "-23345850016.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print (derivative)\n",
    "print (-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "            # Update the features weight\n",
    "            weights[i] = weights[i] - step_size*derivative\n",
    "            # add the squared value of the derivative to the gradient magnitude (for assessing convergence)\n",
    "            gradient_sum_squares += derivative*derivative\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            \n",
    "        # compute the square-root of the gradient sum of squares to get the gradient matnigude:\n",
    "        gradient_magnitude = math.sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88716555    281.91211918]\n"
     ]
    }
   ],
   "source": [
    "my_computed_weights = regression_gradient_descent(simple_feature_matrix , output , initial_weights , step_size , tolerance)\n",
    "print(my_computed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 356134.443255    784640.86440132  435069.83662406 ...,  663418.65315598\n",
      "  604217.10812919  240550.47439317]\n"
     ]
    }
   ],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)\n",
    "test_predictions = predict_output(test_simple_feature_matrix , my_computed_weights)\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75400044902e+14\n"
     ]
    }
   ],
   "source": [
    "test_RSS = np.dot(test_output-test_predictions , test_output-test_predictions)\n",
    "print(test_RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -9.99999688e+04   2.45072603e+02   6.52795267e+01]\n"
     ]
    }
   ],
   "source": [
    "model_2_weights = regression_gradient_descent(feature_matrix , output , initial_weights , step_size , tolerance)\n",
    "print(model_2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 366651.41162949  762662.39850726  386312.09557541 ...,  682087.39916306\n",
      "  585579.27901327  216559.20391786]\n"
     ]
    }
   ],
   "source": [
    "(test_simple_feature_matrix_model_2, test_output_model_2) = get_numpy_data(test_data, model_features, my_output)\n",
    "test_predictions_model_2 = predict_output(test_simple_feature_matrix_model_2 , model_2_weights)\n",
    "print(test_predictions_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7026344363e+14\n"
     ]
    }
   ],
   "source": [
    "test_RSS_model_2 = np.dot(test_output_model_2-test_predictions_model_2 , test_output_model_2-test_predictions_model_2)\n",
    "print(test_RSS_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        310000\n",
      "1        650000\n",
      "2        233000\n",
      "3        580500\n",
      "4        535000\n",
      "5        605000\n",
      "6        775000\n",
      "7        292500\n",
      "8        289000\n",
      "9        571000\n",
      "10       349000\n",
      "11       360000\n",
      "12       243500\n",
      "13       247500\n",
      "14       470000\n",
      "15       480000\n",
      "16       770000\n",
      "17       519950\n",
      "18       527700\n",
      "19       420000\n",
      "20       890000\n",
      "21       282950\n",
      "22       255000\n",
      "23       420000\n",
      "24       807100\n",
      "25       284000\n",
      "26       917500\n",
      "27       425000\n",
      "28       260000\n",
      "29       297000\n",
      "         ...   \n",
      "4199     436952\n",
      "4200     435000\n",
      "4201     349000\n",
      "4202     450000\n",
      "4203     337500\n",
      "4204     850000\n",
      "4205     579000\n",
      "4206     890776\n",
      "4207     810000\n",
      "4208     600000\n",
      "4209     406000\n",
      "4210    1378000\n",
      "4211     579950\n",
      "4212    1450000\n",
      "4213     670000\n",
      "4214     459000\n",
      "4215     589999\n",
      "4216     388000\n",
      "4217     305000\n",
      "4218     337000\n",
      "4219    1700000\n",
      "4220     399950\n",
      "4221     579000\n",
      "4222     490000\n",
      "4223     399950\n",
      "4224    1088000\n",
      "4225     350000\n",
      "4226     610685\n",
      "4227     400000\n",
      "4228     402101\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
