{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data_small.csv')\n",
    "#train_data , test_data = train_test_split(sales, test_size=0.2)\n",
    "train_data = pd.read_csv('kc_house_data_small_train.csv')\n",
    "test_data = pd.read_csv('kc_house_data_small_test.csv')\n",
    "cv_data = pd.read_csv('kc_house_data_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    data_frame['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_frame = data_frame[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_array = data_frame[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_array.as_matrix()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis=0)\n",
    "    normalized_features = features / norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train_data, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test_data, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(cv_data, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train)\n",
    "features_test = features_test / norms\n",
    "features_valid = features_valid / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n",
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print (features_test[0])\n",
    "print (features_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05972359371398078\n"
     ]
    }
   ],
   "source": [
    "x = (features_test[0] - features_train[9])**2\n",
    "euc_dist = math.sqrt(np.sum(x))\n",
    "print(euc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06027470916295592\n",
      "0.08546881147643746\n",
      "0.06149946435279315\n",
      "0.05340273979294363\n",
      "0.05844484060170442\n",
      "0.059879215098128345\n",
      "0.05463140496775461\n",
      "0.055431083236146074\n",
      "0.052383627840220305\n",
      "0.05972359371398078\n"
     ]
    }
   ],
   "source": [
    "for i in range(10) :\n",
    "    x = (features_test[0] - features_train[i])**2\n",
    "    euc_dist = math.sqrt(np.sum(x))\n",
    "    print(euc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06027471  0.08546881  0.06149946  0.05340274  0.05844484  0.05987922\n",
      "  0.0546314   0.05543108  0.05238363  0.05972359]\n"
     ]
    }
   ],
   "source": [
    "x = (features_train[0:10] - features_test[0])**2\n",
    "euc_dist = np.sqrt(np.sum(x, axis=1))\n",
    "print(euc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distances(features_instances, features_query):\n",
    "    x = (features_instances[:] - features_query)**2\n",
    "    distances = np.sqrt(np.sum(x,axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00286049555751 382\n"
     ]
    }
   ],
   "source": [
    "distances = compute_distances(features_train , features_test[2])\n",
    "min = distances[0]\n",
    "min_index=0\n",
    "for i in range(len(distances)) :\n",
    "    if distances[i] < min :\n",
    "        min = distances[i]\n",
    "        min_index=i\n",
    "print(min, min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249000\n"
     ]
    }
   ],
   "source": [
    "print(output_train[382])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, feature_train, features_query):\n",
    "    x = (features_train[:] - features_query)**2\n",
    "    distances = np.sqrt(np.sum(x,axis=1))\n",
    "    distance_tuple = []\n",
    "    for i in range(len(distances)) :\n",
    "        distance_tuple.append((i, distances[i]))\n",
    "    distance_tuple.sort(key = lambda value : value[1])\n",
    "    return distance_tuple[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(382, 0.0028604955575117085), (1149, 0.0032258402701799303), (4087, 0.0035021563333717835), (3142, 0.0035931538334055863)]\n"
     ]
    }
   ],
   "source": [
    "output = k_nearest_neighbors(4, features_train, features_test[2])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    output = k_nearest_neighbors(k, features_train, features_query)\n",
    "    prediction = 0.0\n",
    "    for i in range(k) :\n",
    "        prediction += output_train[output[i][0]]\n",
    "    prediction /= k\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413987.5\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output_of_query(4, features_train, output_train, features_test[2])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(k, features_train, output_train, features_query):\n",
    "    predictions=[]\n",
    "    for i in range(len(features_query)) :\n",
    "        predictions.append(predict_output_of_query(k, features_train, output_train, features_query[i, :]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[881300.0, 431860.0, 460595.0, 430200.0, 766750.0, 667420.0, 350032.0, 512800.70000000001, 484000.0, 457235.0]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_output(10, features_train, output_train, features_test[0:10, :])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350032.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05451197752e+14\n",
      "8.3445073504e+13\n",
      "7.26920960192e+13\n",
      "7.19348033496e+13\n",
      "6.98465174197e+13\n",
      "6.8903104922e+13\n",
      "6.83383144186e+13\n",
      "6.73616787355e+13\n",
      "6.8372727959e+13\n",
      "6.93335579816e+13\n",
      "6.95238552156e+13\n",
      "6.90519486845e+13\n",
      "7.00112545083e+13\n",
      "7.09115306803e+13\n",
      "7.11087974867e+13\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,16) :\n",
    "    predictions = predict_output(k, features_train, output_train, features_valid)\n",
    "    RSS = sum((predictions-output_valid)*(predictions-output_valid))\n",
    "    print(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33091689367e+14\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(8, features_train, output_train, features_test)\n",
    "RSS = sum((test_predictions-output_test)**2)\n",
    "print(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
